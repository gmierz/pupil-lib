## YAML Config Documentation


    # Introduction

    This type of configuration can be used for running specific parameters on different
    portions of the data. They can either be specified at the dataset-specifc level, eye-specific,
    trigger-specifc, or trial-specifc level. And furthermore, this can be set on any number of
    datasets, regardless of previously being processed. For example, if you want to perform a specific
    type of smoothing on a specific trial before it's placed into a trigger-wide data matrix, you can
    specify it here. This tool also allows you to process multiple different triggers across any
    number of datasets.


    # Schema

    Below, is the structure of what is expected by the program when the '--run-config'
    argument is given:

    config:
        Optional(workers: <Int>)
        Optional(logger: AnyOf('default', 'stdout'))
        Optional But Recommended(
            artifact_directory: <String>
        )
        Optional(trial_time: <Int>)
        Optional(baseline_time: <Int>)
        Optional(
            triggers:
                -- Names of triggers in each dataset.
                - <String>
                - <String>
                - ...
        )

        Optional(
            dataset_(pre and/or post)_processing:
                -- List of processing functions to run while epoching an entire dataset.
                -- For before (pre), use dataset_pre_processing, and for after (post)
                -- use dataset_post_processing. Use None in the list to indicate that no
                -- processing functions should be run. These lists are ordered, and that
                -- means that any item that is above another item, runs before the lower
                -- item.
                - <String>
                - <String>
                - ...
        )

        Optional(
            eye_(pre and/or post)_processing:
                -- List of processing functions to run before and after epoching an eye.
                -- For before (pre), use eye_pre_processing, and for after (post)
                -- use eye_post_processing. Use None in the list to indicate that no
                -- processing functions should be run. These lists are ordered, and that
                -- means that any item that is above another item, runs before the lower
                -- item.
                - <String>
                - <String>
                - ...
        )

        Optional(
            trigger_(pre and/or post)_processing:
                -- List of processing functions to run before and after epoching a trigger.
                -- For before (pre), use trigger_pre_processing, and for after (post)
                -- use trigger_post_processing. Use None in the list to indicate that no
                -- processing functions should be run. These lists are ordered, and that
                -- means that any item that is above another item, runs before the lower
                -- item.
                - <String>
                - <String>
                - ...
        )

        Optional(
            trial_(pre and/or post)_processing:
                -- List of processing functions to run before and after epoching a trial.
                -- For before (pre), use trial_pre_processing, and for after (post)
                -- use trial_post_processing. Use None in the list to indicate that no
                -- processing functions should be run. These lists are ordered, and that
                -- means that any item that is above another item, runs before the lower
                -- item.
                - <String>
                - <String>
                - ...
        )



    dataset_name:
        Required if not given in config field (
            dataset_path: <String> 
            trial_time: <Double>                -- Used as default value
            baseline_time: <Double>             -- Used as default value
            processed: AnyOf(true, false)       -- Tells us if the dataset was already processed.
                                                -- Still needs default times if its been processed,
                                                -- specify them through the rest of the configuration.
        )

        Optional(
            dataset_(pre and/or post)_processing:
                - <String>
                - <String>
                - ...
        )

        Optional(
            eye_(pre and/or post)_processing:
                - <String>
                - <String>
                - ...
        )

        Optional(
            trigger_(pre and/or post)_processing:
                - <String>
                - <String>
                - ...
        )

        Optional(
            trial_(pre and/or post)_processing:
                - <String>
                - <String>
                - ...
        )

        Either (
            triggers:
                -- Name of the trigger
                - <String>
                - <String>
                - ...
        ) Or (
            -- It must be defined in the eyes
        )

        Optional (
            eye0:
                Optional(trial_time: <Int>)
                Optional(baseline_time: <Int>)

                Optional(
                    eye_(pre and/or post)_processing:
                        - <String>
                        - <String>
                        - ...
                )

                Optional(
                    trigger_(pre and/or post)_processing:
                        - <String>
                        - <String>
                        - ...
                )

                Optional(
                    trial_(pre and/or post)_processing:
                        - <String>
                        - <String>
                        - ...
                )

                Required if not given in dataset_name (top-level) (
                    triggers:
                        trigger_name:
                            Optional(trial_time: <Int>)
                            Optional(baseline_time: <Int>)

                            Optional(
                                trigger_(pre and/or post)_processing:
                                    - <String>
                                    - <String>
                                    - ...
                            )

                            Optional(
                                trial_(pre and/or post)_processing:
                                    - <String>
                                    - <String>
                                    - ...
                            )

                            Optional(
                                trials:
                                    -- An integer number of the trial of it's
                                    -- order in all trials in increasing order
                                    -- by time.
                                    trial_num:
                                        Optional(trial_time: <Int>)
                                        Optional(baseline_time: <Int>)
                                        Optional(
                                            trial_(pre and/or post)_processing:
                                                - <String>
                                                - <String>
                                                - ...
                                        )
                                    trial_num:
                                        ...same as above.
                            )
                        trigger_name:
                            ...same as above.
                ) And/Or (
                    triggers_list:
                        - <String>
                        - <String>
                )
        )

        Optional (
            eye1:
                ...same as above.
        )
    dataset_name:
        ...same as above.


    # Description

    There can be any number of datasets specified with this. Each of them will be processed
    with either just the default values (along with default pre-/post- prcoessing), or with more
    specific values that are specified deeper within the structure. Those specifics start of
    with either eye0 or eye1, then per trigger name, and finally per trial number in increasing time.

    At each level, more and more specific functionality can be implemented, and other attributes
    can be overwritten. For example, we can specify that some X, and Y triggers must be
    segmented with different baseline and trial times, or use diffent pre and post processing
    functions on specific trials. This could allow you to perhaps smooth data before it's resized,
    or even resample it. This will also allow you to modify the data returned at each stage of the process.
    The `*_pre_processing` and `*_post_processing` flags are used to deliver most of that functionality.

    As the YAML conifig is parsed, the values that are defined at the previous level are
    considered as defaults for the current level. For example, if the trial and baseline times
    are defined at the trigger level, all of it's trials will use those settings, unless
    otherwise specified in a trial number entry.


    # Example

    The best way to explain how to use this schema is through examples.

    1) Specify multiple datatsets:

        -- Setting the times and triggers here, makes
        -- each dataset use them as the default.
        config:
            -- Maximum number of workers
            workers: 100
            -- Log to file
            logger: default

            -- Time after trigger marker
            trial_time: 2
            -- Time before the trigger marker
            baseline_time: -1
            triggers:
                - S11
                - S12
                - S13
                - S14
            -- This specifies that all trials in all datasets must run that additional processing function
            -- either before or after the trial is obtained, along with the default processing.
            trial_processing:
                - default  -- Always needs to be specified if you are modifying the default functions.
                - get_sums -- A function that will take the sum of the data values in the time series chunk.

        dataset1:
            dataset_path: C:\Recordings\CurrentStudy\001\block.xdf

        dataset2:
            dataset_path: C:\Recordings\CurrentStudy\002\block.xdf

        dataset3:
            dataset_path: C:\Recordings\CurrentStudy\003\block.xdf
